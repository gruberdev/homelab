name: "gpt-3.5-turbo"
description: |
  Example Model
license: "Apache 2.0"
urls:
- https://github.com/lm-sys/FastChat
config_file: |
  backend: llama
  parameters:
    model: gpt-3.5-turbo
    top_k: 80
    temperature: 0.2
    top_p: 0.7
  context_size: 1024
  template:
    completion: vicuna-completion
    chat: vicuna-chat

files:
- filename: "gpt-3.5-turbo"
  uri: "https://huggingface.co/TheBloke/Wizard-Vicuna-7B-Uncensored-GGML/resolve/main/Wizard-Vicuna-7B-Uncensored.ggmlv3.q5_0.bin"


prompt_templates:
- name: "vicuna-completion"
  content: |
    {{.Input}}

- name: "vicuna-chat"
  content: |
    Below is an instruction that describes a task. Write a response that appropriately completes the request.

    ### Instruction:
    {{.Input}}

    ### Response:
