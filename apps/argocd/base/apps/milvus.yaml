apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: milvus
spec:
  project: apps
  source:
    repoURL: https://github.com/milvus-io/milvus-helm.git
    targetRevision: milvus-4.0.12
    path: charts/milvus
    helm:
      releaseName: milvus
      values: |
        nodeSelector:
          kubernetes.io/arch: amd64
        attu:
          enabled: true
          name: attu
          image:
            repository: zilliz/attu
            tag: v2.2.4
            pullPolicy: IfNotPresent
          service:
            type: ClusterIP
            port: 3000
          resources:
            limits:
              cpu: 350m
              memory: 512Mi
            requests:
              cpu: 150m
              memory: 128Mi
          ingress:
            enabled: false
        cluster:
          enabled: false
        dataCoordinator:
          enabled: false
        dataNode:
          activeStandby:
            enabled: false
          enabled: true
          heaptrack:
            enabled: false
          profiling:
            enabled: false
          replicas: 1
          resources:
            limits:
              cpu: 550m
              memory: 2048Mi
            requests:
              cpu: 150m
              memory: 512Mi
        etcd:
          auth:
            rbac:
              enabled: false
          autoCompactionMode: revision
          autoCompactionRetention: "1000"
          enabled: true
          extraEnvVars:
          - name: ETCD_QUOTA_BACKEND_BYTES
            value: "4294967296"
          - name: ETCD_HEARTBEAT_INTERVAL
            value: "500"
          - name: ETCD_ELECTION_TIMEOUT
            value: "2500"
          image:
            pullPolicy: Always
            repository: milvusdb/etcd
            tag: 3.5.5-r2
          name: etcd
          pdb:
            create: false
          persistence:
            accessMode: ReadWriteOnce
            enabled: true
            size: 10Gi
          replicaCount: 1
          service:
            peerPort: 2380
            port: 2379
            type: ClusterIP
        externalS3:
          accessKey: <path:kv/data/velero#id>
          bucketName: milvus-wa
          cloudProvider: aws
          enabled: true
          host: ewr1.vultrobjects.com
          port: "443"
          secretKey: <path:kv/data/velero#key>
          useIAM: false
          useSSL: true
        extraConfigFiles:
          user.yaml: |
        heaptrack:
          image:
            pullPolicy: IfNotPresent
            repository: milvusdb/heaptrack
            tag: v0.1.0
        image:
          all:
            pullPolicy: IfNotPresent
            repository: milvusdb/milvus
            tag: v2.2.4
          tools:
            pullPolicy: IfNotPresent
            repository: milvusdb/milvus-config-tool
            tag: v0.1.1
        indexCoordinator:
          enabled: false
        indexNode:
          disk:
            enabled: true
            size:
              enabled: true
          enabled: true
          heaptrack:
            enabled: false
          profiling:
            enabled: false
          replicas: 1
          resources:
            limits:
              cpu: 550m
              ephemeral-storage: 35Gi
              memory: 2048Mi
            requests:
              cpu: 250m
              memory: 512Mi
        ingress:
          enabled: false
        kafka:
          defaultReplicationFactor: 1
          enabled: false
          extraEnvVars:
          - name: KAFKA_CFG_MAX_PARTITION_FETCH_BYTES
            value: "5242880"
          - name: KAFKA_CFG_MAX_REQUEST_SIZE
            value: "5242880"
          - name: KAFKA_CFG_REPLICA_FETCH_MAX_BYTES
            value: "10485760"
          - name: KAFKA_CFG_FETCH_MESSAGE_MAX_BYTES
            value: "5242880"
          - name: KAFKA_CFG_LOG_ROLL_HOURS
            value: "24"
          heapOpts: -Xmx4096m -Xms4096m
          image:
            repository: bitnami/kafka
            tag: 3.1.0-debian-10-r52
          logRetentionBytes: _-1
          logRetentionHours: 168
          maxMessageBytes: _10485760
          metrics:
            jmx:
              enabled: false
              image:
                repository: bitnami/jmx-exporter
                tag: 0.16.1-debian-10-r245
            kafka:
              enabled: false
              image:
                repository: bitnami/kafka-exporter
                tag: 1.4.2-debian-10-r182
            serviceMonitor:
              enabled: false
          name: kafka
          offsetsTopicReplicationFactor: 1
          pdb:
            create: false
          persistence:
            accessMode: ReadWriteOnce
            enabled: true
            size: 50Gi
          replicaCount: 1
          service:
            ports:
              client: 9092
            type: ClusterIP
          startupProbe:
            enabled: true
          terminationGracePeriodSeconds: "90"
          zookeeper:
            enabled: true
            replicaCount: 1
        livenessProbe:
          enabled: true
          failureThreshold: 5
          initialDelaySeconds: 90
          periodSeconds: 30
          successThreshold: 1
          timeoutSeconds: 5
        log:
          file:
            maxAge: 10
            maxBackups: 20
            maxSize: 300
          format: text
          level: info
          persistence:
            annotations:
              helm.sh/resource-policy: keep
            enabled: false
            mountPath: /milvus/logs
            persistentVolumeClaim:
              existingClaim: milvus-storage
        metrics:
          enabled: true
          serviceMonitor:
            enabled: false
            interval: 30s
            scrapeTimeout: 10s
        minio:
          enabled: false
        mysql:
          architecture: replication
          auth:
            createDatabase: true
            database: milvus_meta
            rootPassword: ChangeMe
          enabled: false
          image:
            repository: bitnami/mysql
            tag: 8.0.23-debian-10-r84
          maxIdleConns: 5
          maxOpenConns: 20
          name: mysql
          primary:
            name: primary
            persistence:
              accessModes:
              - ReadWriteOnce
              enabled: true
              size: 10Gi
            resources:
              limits:
                cpu: 350m
                memory: 512Mi
              requests:
                cpu: 150m
                memory: 128Mi
          secondary:
            name: secondary
            persistence:
              accessModes:
              - ReadWriteOnce
              enabled: true
              size: 100Gi
            replicaCount: 1
        proxy:
          enabled: true
          heaptrack:
            enabled: false
          http:
            debugMode:
              enabled: false
            enabled: true
          profiling:
            enabled: false
          replicas: 1
          resources:
            limits:
              cpu: 350m
              memory: 1024Mi
            requests:
              cpu: 150m
              memory: 2568Mi
        pulsar:
          affinity:
            anti_affinity: false
          autorecovery:
            resources:
              limits:
                cpu: 350m
                memory: 512Mi
              requests:
                cpu: 150m
                memory: 128Mi
          bookkeeper:
            configData:
              PULSAR_GC: |
                -Dio.netty.leakDetectionLevel=disabled -Dio.netty.recycler.linkCapacity=1024 -XX:+UseG1GC -XX:MaxGCPauseMillis=10 -XX:+ParallelRefProcEnabled -XX:+UnlockExperimentalVMOptions -XX:+DoEscapeAnalysis -XX:ParallelGCThreads=32 -XX:ConcGCThreads=32 -XX:G1NewSizePercent=50 -XX:+DisableExplicitGC -XX:-ResizePLAB -XX:+ExitOnOutOfMemoryError -XX:+PerfDisableSharedMem -XX:+PrintGCDetails
              PULSAR_MEM: |
                -Xms1024m -Xmx1024m -XX:MaxDirectMemorySize=512m
              nettyMaxFrameSizeBytes: "104867840"
            pdb:
              usePolicy: false
            replicaCount: 1
            resources:
              limits:
                cpu: 350m
                memory: 1024Mi
              requests:
                cpu: 150m
                memory: 128Mi
            volumes:
              journal:
                name: journal
                size: 10Gi
              ledgers:
                name: ledgers
                size: 20Gi
          broker:
            component: broker
            configData:
              PULSAR_GC: |
                -Dio.netty.leakDetectionLevel=disabled -Dio.netty.recycler.linkCapacity=1024 -XX:+ParallelRefProcEnabled -XX:+UnlockExperimentalVMOptions -XX:+DoEscapeAnalysis -XX:ParallelGCThreads=32 -XX:ConcGCThreads=32 -XX:G1NewSizePercent=50 -XX:+DisableExplicitGC -XX:-ResizePLAB -XX:+ExitOnOutOfMemoryError
              PULSAR_MEM: |
                -Xms4096m -Xmx4096m -XX:MaxDirectMemorySize=8192m
              backlogQuotaDefaultLimitGB: "8"
              backlogQuotaDefaultRetentionPolicy: producer_exception
              defaultRetentionSizeInMB: "-1"
              defaultRetentionTimeInMinutes: "10080"
              maxMessageSize: "104857600"
              subscriptionExpirationTimeMinutes: "30"
              ttlDurationDefaultInSeconds: "259200"
            pdb:
              usePolicy: false
            podMonitor:
              enabled: false
            replicaCount: 1
            resources:
              limits:
                cpu: 350m
                memory: 1024Mi
              requests:
                cpu: 150m
                memory: 256Mi
          components:
            autorecovery: true
            bookkeeper: true
            broker: true
            functions: false
            proxy: true
            pulsar_manager: false
            toolset: false
            zookeeper: true
          enabled: false
          images:
            autorecovery:
              pullPolicy: IfNotPresent
              repository: apachepulsar/pulsar
              tag: 2.8.2
            bookie:
              pullPolicy: IfNotPresent
              repository: apachepulsar/pulsar
              tag: 2.8.2
            broker:
              pullPolicy: IfNotPresent
              repository: apachepulsar/pulsar
              tag: 2.8.2
            proxy:
              pullPolicy: IfNotPresent
              repository: apachepulsar/pulsar
              tag: 2.8.2
            pulsar_manager:
              pullPolicy: IfNotPresent
              repository: apachepulsar/pulsar-manager
              tag: v0.1.0
            zookeeper:
              pullPolicy: IfNotPresent
              repository: apachepulsar/pulsar
              tag: 2.8.2
          maxMessageSize: 5242880
          monitoring:
            alert_manager: false
            grafana: false
            node_exporter: false
            prometheus: false
          name: pulsar
          persistence: true
          proxy:
            podMonitor:
              enabled: false
            replicaCount: 1
          pulsar_manager:
            service:
              type: ClusterIP
          pulsar_metadata:
            component: pulsar-init
            image:
              repository: apachepulsar/pulsar
              tag: 2.8.2
          rbac:
            enabled: false
            limit_to_namespace: true
            psp: false
          resources:
            configData:
              PULSAR_GC: |
                -XX:MaxDirectMemorySize=1024m
              PULSAR_MEM: |
                -Xms1024 -Xmx1024m
              httpNumThreads: "100"
            pdb:
              usePolicy: false
            ports:
              pulsar: 6650
            service:
              type: ClusterIP
          zookeeper:
            configData:
              PULSAR_GC: |
                -Dcom.sun.management.jmxremote -Djute.maxbuffer=10485760 -XX:+ParallelRefProcEnabled -XX:+UnlockExperimentalVMOptions -XX:+DoEscapeAnalysis -XX:+DisableExplicitGC -XX:+PerfDisableSharedMem -Dzookeeper.forceSync=no
              PULSAR_MEM: |
                -Xms1024m -Xmx1024m
            pdb:
              usePolicy: false
            resources:
              requests:
                cpu: 100m
                memory: 350Mi
              limits:
                cpu: 350m
                memory: 1024Mi
        queryCoordinator:
          enabled: false
        queryNode:
          disk:
            enabled: true
            size:
              enabled: false
          enabled: true
          heaptrack:
            enabled: false
          profiling:
            enabled: false
          replicas: 1
          resources:
            limits:
              cpu: 350m
              ephemeral-storage: 35Gi
              memory: 1024Mi
            requests:
              cpu: 150m
              memory: 128Mi
        readinessProbe:
          enabled: true
          failureThreshold: 5
          initialDelaySeconds: 90
          periodSeconds: 10
          successThreshold: 1
          timeoutSeconds: 5
        rootCoordinator:
          enabled: false
        service:
          loadBalancerSourceRanges:
          - 0.0.0.0/0
          port: 19530
          type: ClusterIP
        serviceAccount:
          create: false
        standalone:
          disk:
            enabled: true
            size:
              enabled: true
          heaptrack:
            enabled: false
          messageQueue: rocksmq
          persistence:
            annotations:
              helm.sh/resource-policy: keep
            enabled: true
            mountPath: /var/lib/milvus
            persistentVolumeClaim:
              existingClaim: milvus-storage
          profiling:
            enabled: false
          replicas: 1
          resources:
            limits:
              cpu: 1000m
              ephemeral-storage: 35Gi
              memory: 2048Mi
            requests:
              cpu: 350m
              memory: 512Mi
  destination:
    namespace: milvus-system
    name: in-cluster
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
      allowEmpty: true
    syncOptions:
    - Validate=false
    - CreateNamespace=true
    - PrunePropagationPolicy=foreground
    - PruneLast=false
    - ApplyOutOfSyncOnly=false
    - Prune=true
    retry:
      limit: 3
      backoff:
        duration: 60s
        factor: 2
        maxDuration: 15m
