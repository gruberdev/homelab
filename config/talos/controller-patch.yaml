cluster:
  controlPlane:
    endpoint: https://192.168.1.2:6443
    localAPIServerPort: 6443
  clusterName: homelab
  network:
    dnsDomain: cluster.local
    podSubnets:
      - 10.42.0.0/16
    serviceSubnets:
      - 10.43.0.0/16
    cni:
      name: none
  controllerManager:
    image: registry.k8s.io/kube-controller-manager:v1.29.1
    resources:
      requests:
        cpu: 500m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi
  coreDNS:
    image: registry.k8s.io/coredns/coredns:v1.11.1
  apiServer:
    image: registry.k8s.io/kube-apiserver:v1.29.1
    certSANs:
      - 192.168.1.2
      - 192.168.1.4
      - 192.168.1.10
    resources:
      requests:
        cpu: 200m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 768Mi
  allowSchedulingOnControlPlanes: true
  adminKubeconfig:
    # 5 Years
    certLifetime: 43800h0m0s
  extraManifests:
    # https://github.com/alex1989hu/kubelet-serving-cert-approver/releases
    - https://raw.githubusercontent.com/alex1989hu/kubelet-serving-cert-approver/v0.8.0/deploy/standalone-install.yaml
    # https://github.com/kubernetes-sigs/metrics-server/releases
    - https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.7.0/components.yaml

# iSCSi Democractic-CSI
machine:
  install:
    extensions:
      - image: ghcr.io/siderolabs/iscsi-tools:v0.1.4
      - image: ghcr.io/siderolabs/tailscale:1.56.1
      - image: ghcr.io/siderolabs/nonfree-kmod-nvidia:535.54.03-v1.5.0
      - image: ghcr.io/siderolabs/nvidia-container-toolkit:535.54.03-v1.13.5
      - image: ghcr.io/siderolabs/zfs:2.1.14-v1.6.3
  sysctls:
    # Mayastor
    vm.nr_hugepages: "1024"
    # Nvidia
    net.core.bpf_jit_harden: 1
  nodeLabels:
    # Mayastor
    openebs.io/engine: mayastor
  files:
    # Tailscale
    - content: |
        TS_AUTHKEY=
        TS_ROUTES=10.42.0.0/16,192.168.1.0/24,10.43.0.0/16
        TS_ACCEPT_DNS=true
        TS_HOSTNAME=controller
        TS_KUBE_SECRET=
      permissions: 0o644
      path: /var/etc/tailscale/auth.env
      op: create
  kernel:
    # Nvidia
    modules:
      - name: nvidia
      - name: nvidia_uvm
      - name: nvidia_drm
      - name: nvidia_modeset
  network:
    hostname: controller-one
    interfaces:
      - interface: enp0s1
        addresses:
          - 192.168.1.2
        routes:
          - network: 0.0.0.0/0
            gateway: 10.5.0.1
          - network: 10.2.0.0/16
            gateway: 10.2.0.1
          - network: 192.168.1.0/24
            gateway: 192.168.1.1
  kubelet:
    nodeIP:
      validSubnets:
        # Layer 2
        - 192.168.1.0/24
        # Tailscale
        - 100.64.0.0/10
